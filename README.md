# CAREER-DML: A Framework for Causal Inference on Career Trajectories (v10.0)

**Author:** Rodolf Mikel Ghannam Neto

**Date:** February 20, 2026

---

## 1. Overview

CAREER-DML is a causal inference framework for estimating the impact of career transitions on individual earnings trajectories. It combines Recurrent Neural Network (RNN) embeddings with Double/Debiased Machine Learning (DML) to control for high-dimensional confounding from sequential career histories.

This repository contains the full implementation of the framework, the semi-synthetic data laboratory, and the analysis that produced three core scientific contributions:

1.  **The Sequential Embedding Ordering Phenomenon (SEOP):** A robust empirical finding—observed across three distinct scenarios—that causally-motivated embeddings (VIB) consistently yield *more* estimation bias than simpler predictive embeddings in the DML pipeline for career data. This challenges the direct application of information bottleneck methods (Veitch et al., 2020) to socio-economic trajectories, suggesting that the compression discards precisely the variation needed for debiasing.

2.  **The Signal-to-Noise Frontier:** A characterization of the sample size requirements for detecting realistic, small-magnitude causal effects. Our calibration shows that N > 1,034 is required for θ = 0.08—far exceeding typical survey datasets—providing a rigorous, data-driven justification for the use of large-scale administrative data.

3.  **A Bridge Between Two Cultures:** An explicit conceptual bridge between causal ML (Chernozhukov, Wager) and structural labor economics (Ben-Porath, 1967; Keane & Wolpin, 1997; Autor, Levy & Murnane, 2003). The framework does not implement structural models directly, but it captures empirically what they theorize: the learned embeddings serve as non-parametric analogs of the latent variables that structural economists postulate but rarely observe—human capital stocks, latent occupational types, and task-specific skill bundles. Linear probing experiments confirm that the embeddings encode interpretable economic structure (occupation, industry, tenure) without being explicitly trained on these labels.

This work was developed as a proof-of-concept for a PhD application to Copenhagen Business School (Department of Strategy and Innovation).

### Data Sources

> The project's findings are based on a **semi-synthetic data laboratory**. The simulation's causal structure is known (to validate the methodology), but its parameters are calibrated with two real-world **US** data sources:
> - **National Longitudinal Survey of Youth 1979 (NLSY79):** Provides occupational transition matrices that inform realistic labor market dynamics.
> - **Felten et al. (2021) AI Occupational Exposure (AIOE) scores:** Define the treatment variable as *occupational exposure* to AI—measuring structural changes in task demand at the occupation level, not individual adoption.
>
> This ensures our findings are grounded in realistic labor market structures while providing a known ground truth for rigorous benchmarking.

---

## 2. What We Proved: Key Results

The main results are generated by the `main_calibrated.py` script, which runs the final calibrated semi-synthetic DGP (ATE=0.08, N=1,000, φ_dim=64 for all models).

**Table 1: Gain Decomposition of ATE Estimation Methods**

| Method | Type | Sequential? | ATE | Bias | |Bias|% |
|:---|:---|:---:|:---:|:---:|:---:|
| 1. Heckman Two-Step | Parametric | No | 0.8365 | 0.7565 | 945.6% |
| 2. LASSO + DML | Semi-parametric | No | 0.0362 | -0.0438 | 54.8% |
| 3. Random Forest + DML | Non-parametric | No | 0.0260 | -0.0540 | 67.5% |
| 4. Static Embedding + DML | Embedding | No | 0.0032 | -0.0768 | 96.0% |
| 5. Predictive GRU + DML | Embedding | Yes | -0.0174 | -0.0974 | 121.8% |
| 6. Causal GRU VIB + DML | Embedding | Yes | -0.0485 | -0.1285 | 160.6% |
| 7. Debiased GRU + DML | Embedding | Yes | -0.0093 | -0.0893 | 111.6% |

**Key Insights:**
- **Order-of-Magnitude Bias Reduction:** All modern ML methods dramatically outperform the classical Heckman model, reducing estimation bias by an order of magnitude (from 945% to under 60% for the best performers).
- **SEOP Confirmed:** The VIB model (160.6% bias) consistently underperforms the simpler Predictive GRU (121.8%)—even with equal dimensionality. This challenges the intuition that causally-motivated representations should improve causal estimation.
- **At N=1,000**, the simpler LASSO and RF models are the best performers, as the signal is too weak for more complex sequential models to provide incremental benefit. This is precisely the Signal-to-Noise Frontier in action.
- **GATES Heterogeneity Test:** Confirms statistically significant skill-biased treatment effects, consistent with the prediction that AI adoption disproportionately affects workers in routine-intensive occupations.

**Figure 1: Signal-to-Noise Frontier**

![MDE vs N](results/figures/power_analysis_sensitivity.png)

Our power analysis shows that a sample size of **N > 1,034** is required to reliably detect the true ATE of 0.08. This provides a clear, data-driven motivation for the next stage of this research.

---

## 3. Dialogue with Structural Labor Economics

While our approach is from the reduced-form causal ML tradition, it provides an explicit bridge to classical structural models. The learned career embedding, `z`, can be interpreted as a rich, non-parametric approximation of key latent variables that structural economists postulate but rarely observe directly:

-   **Human Capital Stock (Ben-Porath, 1967):** `z` serves as an empirical, high-dimensional measure of an individual's accumulated human capital—the very quantity that the Ben-Porath model defines theoretically but that has eluded direct measurement.
-   **Generalized Mincer Experience (Mincer, 1974):** Our model, `Y = θT + g(z) + ε`, is a non-parametric extension of the Mincer earnings equation, where `g(z)` is a flexible function of a worker's entire career path rather than a polynomial in years of experience.
-   **Latent Occupational Types (Keane & Wolpin, 1997):** `z` implicitly learns a latent type space from sequences of occupational transitions, analogous to the discrete types in structural dynamic programming models.
-   **Task Content of Occupations (Autor, Levy & Murnane, 2003):** `z` captures the task-level structure of occupations through observed transition patterns, providing a data-driven analog to the routine/non-routine task framework.

This dialogue is not merely rhetorical. Linear probing experiments confirm that the embeddings encode interpretable economic structure—occupation, industry, tenure—without being explicitly trained on these labels. The representations are economically meaningful, not statistical artifacts.

---

## 4. The Central Question: What Happens at Population Scale?

The proof-of-concept reaches a productive limit at survey scale. With 34.7% of the Danish workforce already exposed to generative AI in tasks representing 20% or more of their work hours (OECD, 2024), the central question for the PhD is whether these patterns hold when the framework confronts population-scale administrative data.

**The Danish IDA registers** (Integrated Database for Labour Market Research, Statistics Denmark) provide:
- **Scale:** N > 1,000,000 individuals—over 1,000× the Signal-to-Noise Frontier threshold
- **Temporal depth:** T > 30 years of annual observations—enabling life-cycle and dynamic treatment effect analysis
- **Population coverage:** No sampling bias or attrition
- **Occupational classification:** DISCO-08 (Danish adaptation of ISCO-08)—richer variation than NLSY79

**What we expect to produce with Danish data:**

| Contribution | Method | Significance |
|:---|:---|:---|
| Cross the Signal-to-Noise Frontier | N > 1M vs 1,034 minimum | Definitive test of SEOP at scale |
| First population-level causal estimates of AI on careers in Denmark | GATES/CLAN on age, gender, education, region | Which workers benefit, which are displaced, and why |
| Disentangle the GenAI shock | Pre-2022 AIOE baseline → post-2022 trajectories | Clean identification of traditional AI vs GenAI effects |
| Dynamic treatment effects | 30+ years of longitudinal data | Cumulative career impacts, life-cycle heterogeneity |
| Policy simulations | Counterfactual trajectories under varying AI diffusion | Direct input for Danish/EU labor policy |

If the patterns hold, the contribution gains substantive weight. If they do not, the project will have mapped fundamental limits of causal inference in complex economic settings—and mapping frontiers is as valuable as demonstrating superiority.

---

## 5. Repository Structure

- `main_calibrated.py`: Main script to run the final v10.0 pipeline.
- `src/`: Core modules for the framework (DGP, embeddings, DML, validation, power analysis).
- `docs/`: All documentation, including the final PhD application materials.
- `results/`: All outputs from the pipeline runs.
- `tests/`: A suite of 50 unit and integration tests.
- `data/`: Input data for calibration.

## 6. How to Run

1.  Install dependencies:
    ```bash
    pip install -r requirements.txt
    ```
2.  Run the main pipeline:
    ```bash
    python3 main_calibrated.py
    ```
3.  Run the tests:
    ```bash
    pytest
    ```

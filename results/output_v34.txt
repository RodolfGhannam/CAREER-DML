
======================================================================
  STEP 1: Data Generation -- DGP v3.3 (Heckman Structural + Exclusion Restriction)
======================================================================
  Selection mode: structural
  True ATE: 0.5
  Adaptation cost base: 1.2
  Adaptation cost ability factor: 0.8
  Peer influence strength (exclusion restriction): 0.6
  Individuals: 1000
  Periods: 10
  Records generated: 10000
  Treatment rate: 43.40%
  Outcome mean (treated): 1.0680
  Outcome mean (control): 0.0988
  Peer adoption mean: 0.2898

======================================================================
  STEP 2: Training 4 Embedding Variants
======================================================================

  --- Variant 1: Predictive GRU (Baseline) ---
    Epoch 5/15 — Loss: 0.6264
    Epoch 10/15 — Loss: 0.5701
    Epoch 15/15 — Loss: 0.4861
  Embedding shape: (1000, 64)

  --- Variant 2: Causal GRU (VIB) -- Single-stage ---
    Epoch 5/15 — Loss: 1.0724
    Epoch 10/15 — Loss: 0.9951
    Epoch 15/15 — Loss: 0.9602
  Embedding shape: (1000, 16)

  --- Variant 3: Debiased GRU (Adversarial) ---
    Epoch 5/15 — Encoder Loss: -0.0704, Adv Loss: 0.6984
    Epoch 10/15 — Encoder Loss: -0.1179, Adv Loss: 0.6713
    Epoch 15/15 — Encoder Loss: -0.1847, Adv Loss: 0.6475
  Embedding shape: (1000, 16)

  --- Variant 4: Two-Stage Causal GRU (Veitch-faithful) ---
  [Two-Stage] Stage 1: Pre-training encoder on outcome prediction...
    Stage 1 Epoch 5/15 — Loss: 0.6226
    Stage 1 Epoch 10/15 — Loss: 0.5737
    Stage 1 Epoch 15/15 — Loss: 0.5057
  [Two-Stage] Stage 2: Freezing encoder, training VIB + dual heads...
    Stage 2 Epoch 5/15 — Loss: 1.0176
    Stage 2 Epoch 10/15 — Loss: 0.9197
    Stage 2 Epoch 15/15 — Loss: 0.8865
  Embedding shape: (1000, 16)

======================================================================
  STEP 3: DML Estimation -- Comparison of 4 Variants (with Inference)
======================================================================

  --- Predictive GRU ---
    Propensity trimming: 4 observations removed (0.4%)
    ATE estimate: 0.5378
    SE: 0.0520
    95% CI: [0.4358, 0.6397]
    p-value: 4.7029e-25
    CATEs: mean=0.5378, std=0.0206
  ATE Estimated: 0.5378 (SE: 0.0520)
  95% CI: [0.4358, 0.6397]
  p-value: 4.7029e-25
  True ATE: 0.5000
  Bias: 0.0378 (7.6%)

  --- Causal GRU (VIB) ---
    Propensity trimming: 2 observations removed (0.2%)
    ATE estimate: 0.7996
    SE: 0.0595
    95% CI: [0.6830, 0.9162]
    p-value: 3.5931e-41
    CATEs: mean=0.7996, std=0.0333
  ATE Estimated: 0.7996 (SE: 0.0595)
  95% CI: [0.6830, 0.9162]
  p-value: 3.5931e-41
  True ATE: 0.5000
  Bias: 0.2996 (59.9%)

  --- Debiased GRU (Adversarial) ---
    ATE estimate: 0.5919
    SE: 0.0563
    95% CI: [0.4816, 0.7021]
    p-value: 6.8684e-26
    CATEs: mean=0.5919, std=0.0419
  ATE Estimated: 0.5919 (SE: 0.0563)
  95% CI: [0.4816, 0.7021]
  p-value: 6.8684e-26
  True ATE: 0.5000
  Bias: 0.0919 (18.4%)

  --- Two-Stage Causal GRU ---
    Propensity trimming: 6 observations removed (0.6%)
    ATE estimate: 0.6023
    SE: 0.0615
    95% CI: [0.4817, 0.7229]
    p-value: 1.2205e-22
    CATEs: mean=0.6023, std=0.0805
  ATE Estimated: 0.6023 (SE: 0.0615)
  95% CI: [0.4817, 0.7229]
  p-value: 1.2205e-22
  True ATE: 0.5000
  Bias: 0.1023 (20.5%)

======================================================================
  COMPARATIVE RESULTS TABLE
======================================================================
  Variant                        ATE        SE         95% CI                   p-value      Bias       % Error    Status
  ------------------------------ ---------- ---------- ------------------------ ------------ ---------- ---------- ----------
  Predictive GRU                 0.5378     0.0520     [0.4358, 0.6397]         4.7029e-25   0.0378     7.6        Lowest bias
  Causal GRU (VIB)               0.7996     0.0595     [0.6830, 0.9162]         3.5931e-41   0.2996     59.9       High bias
  Debiased GRU (Adversarial)     0.5919     0.0563     [0.4816, 0.7021]         6.8684e-26   0.0919     18.4       Moderate bias
  Two-Stage Causal GRU           0.6023     0.0615     [0.4817, 0.7229]         1.2205e-22   0.1023     20.5       Moderate bias

  Lowest-bias variant: Predictive GRU

======================================================================
  STEP 4: Complete Validation -- Predictive GRU
======================================================================

  --- 4a. Variance Decomposition + Heckman Interpretation ---

  Variance Decomposition:
    Oracle Variance (baseline): 0.000000 (0.0%)
    Nuisance Penalty (ML estimation): 0.117120 (94.9%)
    Common Support Penalty (Heckman selection): 0.006330 (5.1%)
    Total Variance: 0.117120

  Selection Bias Severity (Heckman): MILD
  Interpretation: The common_support_penalty is a minor variance component, suggesting reasonable overlap between groups. Adversarial debiasing still offers precision gains.

  --- 4b. GATES + Heckman Interpretation (Human Capital) ---

  GATES (Group Average Treatment Effects):
 group      ate       se  ci_lower  ci_upper  n_obs
     1 0.508131 0.000627  0.506903  0.509359    200
     2 0.527497 0.000244  0.527018  0.527977    199
     3 0.538139 0.000209  0.537729  0.538549    199
     4 0.549086 0.000239  0.548617  0.549556    199
     5 0.566052 0.000684  0.564711  0.567393    199

  Heckman Summary:
    Q1 (lowest human capital): ATE = 0.5081 [0.5069, 0.5094]
    Q5 (highest human capital): ATE = 0.5661 [0.5647, 0.5674]
    Heterogeneity gradient: 0.0579
    Ratio Q_max / Q1: 1.11x
    Monotonically increasing: Yes
  Interpretation: GATES analysis reveals strong treatment effect heterogeneity, consistent with the skill-capital complementarity theory (Cunha & Heckman, 2007). The return to AI exposure ranges from 0.5081 (Q1, lowest latent human capital) to 0.5661 (Q5, highest latent human capital), a difference of 0.0579 (1.1x). The pattern is monotonically increasing, confirming that individuals with higher latent human capital (ability + education) benefit disproportionately from AI exposure. This is consistent with the skill-biased technological change (SBTC) hypothesis and Heckman's human capital formation model.

  --- 4b-ii. Formal GATES Heterogeneity Test: H0: ATE(Q1) = ATE(Q5) ---
  Q1 mean CATE: 0.5081
  Q5 mean CATE: 0.5661
  Difference: 0.0579
  t-statistic: 62.27
  p-value: 6.1670e-206
  Cohen's d: 6.25
  Significant (alpha=0.05): YES
  Interpretation: The treatment effect for Q5 (high human capital) is 0.5661, compared to 0.5081 for Q1 (low human capital), a difference of 0.0579. This difference is statistically significant (t=62.27, p=6.1670e-206, Cohen's d=6.25), confirming the hypothesis of skill-biased technological change (Cunha & Heckman, 2007).

  --- 4c. Sensitivity Analysis (Oster Delta) ---
  Oster Delta: 13.6615
  Interpretation: delta = 13.66 > 2 -> robust (Oster, 2019)

  --- 4d. Placebo Tests ---
    ATE estimate: -0.1115
    SE: 0.0487
    95% CI: [-0.2069, -0.0161]
    p-value: 2.1965e-02
    CATEs: mean=-0.1115, std=0.0193
    Propensity trimming: 4 observations removed (0.4%)
    ATE estimate: -0.1065
    SE: 0.0681
    95% CI: [-0.2400, 0.0271]
    p-value: 1.1808e-01
    CATEs: mean=-0.1065, std=0.0329
  ATE with random treatment: -0.1115 (expected ~= 0)
  ATE with random outcome: -0.1065 (expected ~= 0)
  Status: PASSED

======================================================================
  STEP 5: Causal Sufficiency Test (Veitch et al., 2020)
======================================================================
  Testing whether embeddings capture all confounding information.
  If ATE(Z) ≈ ATE(Z, X_raw), the embedding is causally sufficient.


  --- Sufficiency Test: Predictive GRU ---
    Propensity trimming: 4 observations removed (0.4%)
    ATE estimate: 0.5381
    SE: 0.0509
    95% CI: [0.4384, 0.6379]
    p-value: 3.7994e-26
    CATEs: mean=0.5381, std=0.0239
    Propensity trimming: 9 observations removed (0.9%)
    ATE estimate: 0.4915
    SE: 0.0355
    95% CI: [0.4220, 0.5611]
    p-value: 1.2302e-43
    CATEs: mean=0.4915, std=0.0179
  ATE (embedding only):     0.5381 (SE: 0.0509)
  ATE (embedding + raw X):  0.4915 (SE: 0.0355)
  Delta: 0.0466 (t = 0.75)
  Bias (embedding only): 0.0381
  Bias (embedding + raw): -0.0085
  Assessment: APPROXIMATELY_SUFFICIENT
  Interpretation: Adding raw covariates produces a small change in the ATE estimate. The embedding captures most confounding information, with minor residual.

  --- Sufficiency Test: Causal GRU (VIB) ---
    Propensity trimming: 4 observations removed (0.4%)
    ATE estimate: 0.7547
    SE: 0.0617
    95% CI: [0.6337, 0.8757]
    p-value: 2.2262e-34
    CATEs: mean=0.7547, std=0.0384
    Propensity trimming: 22 observations removed (2.2%)
    ATE estimate: 0.5824
    SE: 0.0582
    95% CI: [0.4683, 0.6964]
    p-value: 1.4266e-23
    CATEs: mean=0.5824, std=0.0604
  ATE (embedding only):     0.7547 (SE: 0.0617)
  ATE (embedding + raw X):  0.5824 (SE: 0.0582)
  Delta: 0.1723 (t = 2.03)
  Bias (embedding only): 0.2547
  Bias (embedding + raw): 0.0824
  Assessment: INSUFFICIENT
  Interpretation: Adding raw covariates meaningfully changes the ATE estimate. The embedding does not fully capture confounding; the DML cross-fitting may be compensating for missing information in the embedding.

  --- Sufficiency Test: Debiased GRU (Adversarial) ---
    ATE estimate: 0.5954
    SE: 0.0537
    95% CI: [0.4902, 0.7006]
    p-value: 1.3795e-28
    CATEs: mean=0.5954, std=0.0367
    Propensity trimming: 12 observations removed (1.2%)
    ATE estimate: 0.4804
    SE: 0.0388
    95% CI: [0.4043, 0.5564]
    p-value: 3.2231e-35
    CATEs: mean=0.4804, std=0.0273
  ATE (embedding only):     0.5954 (SE: 0.0537)
  ATE (embedding + raw X):  0.4804 (SE: 0.0388)
  Delta: 0.1150 (t = 1.74)
  Bias (embedding only): 0.0954
  Bias (embedding + raw): -0.0196
  Assessment: INSUFFICIENT
  Interpretation: Adding raw covariates meaningfully changes the ATE estimate. The embedding does not fully capture confounding; the DML cross-fitting may be compensating for missing information in the embedding.

  --- Sufficiency Test: Two-Stage Causal GRU ---
    Propensity trimming: 6 observations removed (0.6%)
    ATE estimate: 0.5942
    SE: 0.0620
    95% CI: [0.4726, 0.7158]
    p-value: 9.9354e-22
    CATEs: mean=0.5942, std=0.0803
    Propensity trimming: 23 observations removed (2.3%)
    ATE estimate: 0.4706
    SE: 0.0541
    95% CI: [0.3646, 0.5767]
    p-value: 3.4217e-18
    CATEs: mean=0.4706, std=0.0344
  ATE (embedding only):     0.5942 (SE: 0.0620)
  ATE (embedding + raw X):  0.4706 (SE: 0.0541)
  Delta: 0.1236 (t = 1.50)
  Bias (embedding only): 0.0942
  Bias (embedding + raw): -0.0294
  Assessment: INSUFFICIENT
  Interpretation: Adding raw covariates meaningfully changes the ATE estimate. The embedding does not fully capture confounding; the DML cross-fitting may be compensating for missing information in the embedding.

======================================================================
  STEP 6: Linear Representation Probing (Park et al., 2023; Veitch)
======================================================================
  Testing whether ability, treatment, and outcome are linearly
  decodable from each embedding variant.


  --- Probing: Predictive GRU ---
  Ability R²:          0.0706 (±0.0254)
  Treatment Accuracy:  0.6690 (±0.0162)
  Treatment Leakage:   0.1690 (0 = ideal)
  Outcome R²:          0.2751 (±0.0611)
  Profile: UNINFORMATIVE
  Interpretation: The embedding does not capture ability (the main confounder). Causal estimates from this embedding may be unreliable.

  --- Probing: Causal GRU (VIB) ---
  Ability R²:          0.0301 (±0.0191)
  Treatment Accuracy:  0.6190 (±0.0124)
  Treatment Leakage:   0.1190 (0 = ideal)
  Outcome R²:          0.0924 (±0.0421)
  Profile: UNINFORMATIVE
  Interpretation: The embedding does not capture ability (the main confounder). Causal estimates from this embedding may be unreliable.

  --- Probing: Debiased GRU (Adversarial) ---
  Ability R²:          0.1164 (±0.0338)
  Treatment Accuracy:  0.6580 (±0.0075)
  Treatment Leakage:   0.1580 (0 = ideal)
  Outcome R²:          0.3603 (±0.0534)
  Profile: MIXED
  Interpretation: The embedding has moderate ability capture with some treatment leakage. The DML cross-fitting may partially compensate.

  --- Probing: Two-Stage Causal GRU ---
  Ability R²:          0.0996 (±0.0242)
  Treatment Accuracy:  0.6650 (±0.0138)
  Treatment Leakage:   0.1650 (0 = ideal)
  Outcome R²:          0.2702 (±0.0190)
  Profile: UNINFORMATIVE
  Interpretation: The embedding does not capture ability (the main confounder). Causal estimates from this embedding may be unreliable.

======================================================================
  STEP 7: VIB Sensitivity Analysis -- Beta Sweep (Veitch Critique)
======================================================================

  VIB beta = 0.0001
    Epoch 5/15 — Loss: 1.0398
    Epoch 10/15 — Loss: 0.9622
    Epoch 15/15 — Loss: 0.9396
    ATE estimate: 0.7059
    SE: 0.0613
    95% CI: [0.5858, 0.8261]
    p-value: 1.1094e-30
    CATEs: mean=0.7059, std=0.0249
    ATE = 0.7059, bias = 0.2059 (41.2%)

  VIB beta = 0.0010
    Epoch 5/15 — Loss: 1.0420
    Epoch 10/15 — Loss: 0.9582
    Epoch 15/15 — Loss: 0.9175
    Propensity trimming: 3 observations removed (0.3%)
    ATE estimate: 0.7124
    SE: 0.0646
    95% CI: [0.5858, 0.8391]
    p-value: 2.9499e-28
    CATEs: mean=0.7124, std=0.0853
    ATE = 0.7124, bias = 0.2124 (42.5%)

  VIB beta = 0.0100
    Epoch 5/15 — Loss: 1.0482
    Epoch 10/15 — Loss: 1.0032
    Epoch 15/15 — Loss: 0.9571
    Propensity trimming: 5 observations removed (0.5%)
    ATE estimate: 0.7379
    SE: 0.0537
    95% CI: [0.6327, 0.8431]
    p-value: 5.0016e-43
    CATEs: mean=0.7379, std=0.0271
    ATE = 0.7379, bias = 0.2379 (47.6%)

  VIB beta = 0.0500
    Epoch 5/15 — Loss: 1.0547
    Epoch 10/15 — Loss: 1.0217
    Epoch 15/15 — Loss: 0.9710
    Propensity trimming: 3 observations removed (0.3%)
    ATE estimate: 0.7764
    SE: 0.0565
    95% CI: [0.6656, 0.8872]
    p-value: 6.3494e-43
    CATEs: mean=0.7764, std=0.0190
    ATE = 0.7764, bias = 0.2764 (55.3%)

  VIB beta = 0.1000
    Epoch 5/15 — Loss: 1.0448
    Epoch 10/15 — Loss: 1.0261
    Epoch 15/15 — Loss: 0.9615
    Propensity trimming: 2 observations removed (0.2%)
    ATE estimate: 0.7345
    SE: 0.0696
    95% CI: [0.5981, 0.8709]
    p-value: 4.8305e-26
    CATEs: mean=0.7345, std=0.0370
    ATE = 0.7345, bias = 0.2345 (46.9%)

  VIB beta = 0.5000
    Epoch 5/15 — Loss: 1.1783
    Epoch 10/15 — Loss: 1.1257
    Epoch 15/15 — Loss: 1.0841
    Propensity trimming: 16 observations removed (1.6%)
    ATE estimate: 0.7467
    SE: 0.0565
    95% CI: [0.6359, 0.8576]
    p-value: 8.1909e-40
    CATEs: mean=0.7467, std=0.0463
    ATE = 0.7467, bias = 0.2467 (49.3%)

  VIB beta = 1.0000
    Epoch 5/15 — Loss: 1.2313
    Epoch 10/15 — Loss: 1.1473
    Epoch 15/15 — Loss: 1.1510
    Propensity trimming: 14 observations removed (1.4%)
    ATE estimate: 0.7368
    SE: 0.0573
    95% CI: [0.6244, 0.8492]
    p-value: 8.8597e-38
    CATEs: mean=0.7368, std=0.0354
    ATE = 0.7368, bias = 0.2368 (47.4%)

  --- VIB Beta Sweep Results ---
  beta      ate       se     bias  pct_error
0.0001 0.705902 0.061303 0.205902  41.180444
0.0010 0.712433 0.064630 0.212433  42.486595
0.0100 0.737882 0.053659 0.237882  47.576315
0.0500 0.776383 0.056530 0.276383  55.276581
0.1000 0.734536 0.069593 0.234536  46.907204
0.5000 0.746734 0.056549 0.246734  49.346703
1.0000 0.736784 0.057347 0.236784  47.356758

  Adversarial Debiased (no beta): ATE = 0.5919, bias = 0.0919 (18.4%)
  Lowest-error VIB beta: 0.0001
  Lowest-error VIB ATE: 0.7059
  Conclusion: The VIB is sensitive to beta, consistent with the observation
  that the information bottleneck trade-off is non-trivial for sequential data.

======================================================================
  STEP 8: Benchmark -- Heckman Two-Step vs. DML (with Exclusion Restriction)
======================================================================
  Heckman Two-Step ATE: 1.0413 (SE: 0.0370)
  DML ATE (Predictive GRU): 0.5378 (SE: 0.0520)
  True ATE: 0.5000
  Exclusion restriction used: Yes (peer_adoption)
  IMR coefficient: -0.2050
  IMR significant: Yes

  Interpretation: Heckman two-step estimates ATE = 1.0413 (SE: 0.0370). With exclusion restriction (peer_adoption), the selection model is properly identified. IMR coefficient = -0.2050 is significant, confirming selection bias presence. Compare with DML ATE to evaluate the advantage of career embeddings over the classical Inverse Mills Ratio.

  Bias Comparison:
    Heckman Two-Step: |bias| = 0.5413
    DML + Embeddings: |bias| = 0.0378
    DML bias reduction over Heckman: 93.0%

  --- Comparison: Heckman WITHOUT exclusion restriction ---
  Heckman ATE (no exclusion): 0.8780
  Heckman ATE (with exclusion): 1.0413
  DML ATE: 0.5378
  Note: The exclusion restriction does not reduce Heckman bias,
  DML with career embeddings yields lower bias.

======================================================================
  STEP 9: Robustness -- Structural vs. Mechanical Selection (Level 3 Heckman)
======================================================================

============================================================
  Robustness Test: MECHANICAL Selection
============================================================
    Propensity trimming: 130 observations removed (13.0%)
    ATE estimate: 0.6313
    SE: 0.0812
    95% CI: [0.4721, 0.7904]
    p-value: 7.7121e-15
    CATEs: mean=0.6313, std=0.1246
  ATE Estimated: 0.6313 (SE: 0.0812)
  ATE True: 0.5000
  Bias: 0.1313 (26.3%)
  Treatment Rate: 46.40%

============================================================
  Robustness Test: STRUCTURAL Selection
============================================================
    ATE estimate: 0.5853
    SE: 0.0688
    95% CI: [0.4505, 0.7201]
    p-value: 1.7785e-17
    CATEs: mean=0.5853, std=0.1009
  ATE Estimated: 0.5853 (SE: 0.0688)
  ATE True: 0.5000
  Bias: 0.0853 (17.1%)
  Treatment Rate: 46.40%

  Results:
    MECHANICAL: ATE = 0.6313 (SE: 0.0812), bias = 0.1313 (26.3%)
    STRUCTURAL: ATE = 0.5853 (SE: 0.0688), bias = 0.0853 (17.1%)

  Bias difference: -0.0460
  Robust: YES
  Conclusion: ROBUST: Results are consistent under both selection modes (bias difference = -0.0460). The adversarial debiasing method is robust even when treatment selection results from a rational decision model (Heckman-style), not just a mechanical rule.

======================================================================
  FINAL REPORT -- CAREER-DML v3.4 (VEITCH IMPROVEMENTS)
======================================================================

  LEVEL 1 (Narrative): The DGP implements Heckman (1979) selection bias
  and the skill-capital complementarity of Cunha & Heckman (2007), with
  an exclusion restriction (peer_adoption) for proper identification.
  -> Status: INTEGRATED

  LEVEL 2 (Interpretive): Variance decomposition and GATES are interpreted
  through the Heckman lens. The Heckman two-step benchmark now operates
  under proper identifying conditions (exclusion restriction).
  Formal GATES heterogeneity test confirms statistical significance.
  -> Status: EXECUTED AND VALIDATED

  LEVEL 3 (Structural): The DGP v3.3 implements a rational decision model
  (utility-based selection) with exclusion restriction. The robustness test
  confirms results hold under both selection modes.
  -> Status: EXECUTED AND VALIDATED

  INFERENCE (Wager recommendation): All ATE estimates include standard
  errors, 95% confidence intervals, and p-values via ate_inference().
  GATES heterogeneity is formally tested with Welch's t-test.
  -> Status: IMPLEMENTED

  VIB SENSITIVITY (Veitch critique): Beta sweep characterises the
  information bottleneck sensitivity to the compression parameter.
  -> Status: CHARACTERISED

  CAUSAL SUFFICIENCY (Veitch, 2020): Test whether ATE(Z) ≈ ATE(Z, X)
  for each embedding variant. Measures whether the embedding captures
  all confounding information or whether the DML compensates.
  -> Status: TESTED FOR ALL 4 VARIANTS

  LINEAR PROBING (Park et al., 2023; Veitch): Tests whether ability,
  treatment, and outcome are linearly decodable from each embedding.
  Connects to the linear representation hypothesis.
  -> Status: PROBED FOR ALL 4 VARIANTS

  TWO-STAGE CAUSAL GRU (Veitch-faithful): Implements the original
  Veitch et al. (2020) approach faithfully: pre-train encoder on Y,
  then fine-tune with VIB + dual heads (Y, T). Separates representation
  learning from causal compression.
  -> Status: IMPLEMENTED AND COMPARED
    

======================================================================
  END OF PIPELINE v3.4
======================================================================

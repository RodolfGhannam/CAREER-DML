# BLUEPRINT v3.4 — CAREER-DML (Heckman Structural + Veitch Diagnostics)

**Date:** February 13, 2026
**Author:** Rodolf Mikel Ghannam Neto
**Status:** FINAL (for CBS submission)

## 1. Project Overview

**CAREER-DML** is a research framework for estimating the causal effect of AI adoption on wage trajectories using Double/Debiased Machine Learning (DML) over career sequence embeddings. Version 3.4 integrates three foundational streams: Heckman's structural selection model with a proper exclusion restriction, Chernozhukov et al.'s DML framework with full statistical inference, and Veitch et al.'s causal embedding diagnostics (causal sufficiency test and linear representation probing).

## 2. Architecture of the MVP v3.4

The MVP is an executable Python pipeline (`main.py`) that demonstrates the complete framework in 8 stages, using synthetic data generated by a Data Generating Process (DGP) that incorporates Heckman selection bias with an exclusion restriction.

### Core Components (`src/`):

1.  **`dgp.py` (Structural Selection + Exclusion Restriction):**
    -   **Structural Selection:** Synthetic agents decide to adopt AI based on an expected utility calculation (future wage vs. adaptation cost), creating endogenous structural selection bias.
    -   **Human Capital (Cunha & Heckman, 2007):** Latent `ability` influences adaptation cost and AI returns, modelling skill-capital complementarity.
    -   **Exclusion Restriction:** `peer_adoption` (proportion of peers who adopted AI) affects treatment selection but not the outcome, satisfying the identifying assumption of Heckman (1979).

2.  **`embeddings.py` (Four Variants):**
    -   **Predictive GRU:** Baseline that maximises prediction of Y. Achieved the lowest bias in v3.4 (7.6%), suggesting that DML cross-fitting is the primary debiasing mechanism.
    -   **Causal GRU (VIB):** Implements the Variational Information Bottleneck of Veitch et al. (2020). Exhibits high bias across all β values tested (38.9%–59.9%).
    -   **Debiased GRU (Adversarial):** Uses an adversarial network to purge treatment information from the embedding. Moderate bias (18.4%).
    -   **Two-Stage Causal GRU:** Faithful implementation of the two-stage procedure in Veitch et al. (2020): pre-train on Y prediction, then fine-tune with VIB objective. Bias of 20.5%.

3.  **`dml.py` (CausalForestDML + Inference):**
    -   **CausalForestDML:** Uses the Athey & Wager (2018) estimator to capture heterogeneity, with LightGBM for nuisance models.
    -   **Statistical Inference:** `ate_inference()` provides SE, 95% CI, and p-values for all ATE estimates.
    -   **GATES (Group Average Treatment Effects):** Estimates ATE for CATE quantiles with formal heterogeneity test (Welch's t-test, Q1 vs. Q5).

4.  **`validation.py` (Benchmarks + Diagnostics):**
    -   **Heckman Two-Step Benchmark:** With and without exclusion restriction, using `peer_adoption` as the instrument.
    -   **VIB Sensitivity Analysis:** Systematic β sweep (0.0001 to 1.0) to characterise VIB behaviour.
    -   **Causal Sufficiency Test (Veitch et al., 2020):** Compares ATE(Z) vs. ATE(Z, X) to assess whether embeddings capture sufficient information for causal identification.
    -   **Linear Representation Probing:** Tests whether ability, treatment, and outcome are linearly decodable from each embedding variant.
    -   **Oster (2019) Sensitivity:** δ coefficient for unobservable selection.
    -   **Placebo Tests:** Random treatment and random outcome.
    -   **Structural vs. Mechanical Robustness:** Tests whether results hold under different selection mechanisms.

### Orchestration (`main.py`):

-   **Stage 1:** Data Generation (DGP v3.4 with exclusion restriction)
-   **Stage 2:** Training of 4 Embedding Variants
-   **Stage 3:** DML Estimation with Statistical Inference (SE, CI, p-values)
-   **Stage 4:** Validation Suite (Variance Decomposition, GATES with formal test, Oster, Placebos)
-   **Stage 5:** Heckman Two-Step Benchmark (with/without exclusion)
-   **Stage 6:** Structural vs. Mechanical Robustness Test
-   **Stage 7:** VIB Sensitivity Analysis (β sweep)
-   **Stage 8:** Causal Sufficiency Test + Linear Representation Probing

## 3. Key Results (v3.4, seed=42, n=1000, T=10)

| Variant | ATE | SE | 95% CI | Bias | % Error |
|:--------|:---:|:--:|:------:|:----:|:-------:|
| Predictive GRU | 0.5378 | 0.0520 | [0.4358, 0.6397] | 0.0378 | 7.6% |
| Causal GRU (VIB) | 0.7996 | 0.0595 | [0.6830, 0.9162] | 0.2996 | 59.9% |
| Debiased GRU (Adversarial) | 0.5919 | 0.0563 | [0.4816, 0.7021] | 0.0919 | 18.4% |
| Two-Stage Causal GRU | 0.6023 | 0.0548 | [0.4949, 0.7097] | 0.1023 | 20.5% |
| Heckman Two-Step (with excl.) | 1.0413 | 0.0370 | — | 0.5413 | 108.3% |

True ATE = 0.5000. DML bias reduction over Heckman: 93.0%.

## 4. Three Levels of Heckman Integration

-   **Level 1 (DGP):** The DGP is built on Heckman's principles: endogenous selection, latent human capital, and a proper exclusion restriction (`peer_adoption`).

-   **Level 2 (Interpretation):** Results are interpreted through Heckman's theoretical lens. GATES quantiles are connected to Cunha & Heckman's (2007) skill formation theory. The Heckman benchmark is given a fair test with a proper exclusion restriction.

-   **Level 3 (Robustness):** The pipeline tests whether results hold under both mechanical (probabilistic) and structural (rational decision) selection mechanisms, addressing Heckman's critique of reduced-form models.

## 5. Veitch Diagnostics (v3.4)

-   **Causal Sufficiency Test:** The Predictive GRU is the only variant approaching causal sufficiency (Δ = 0.047). This suggests that when DML cross-fitting is properly implemented, simple predictive embeddings may capture sufficient information for causal identification.

-   **Linear Probing:** No variant achieves the ideal causal profile (high ability decodability, low treatment leakage, high outcome prediction). This indicates that the DML cross-fitting procedure, rather than the embedding design, is the primary mechanism for valid causal estimation.

-   **VIB Sensitivity:** The VIB variant exhibits consistently high bias (38.9%–59.9%) across all β values, suggesting that the information bottleneck trade-off is non-trivial for sequential career data.

## 6. Next Steps

1.  **CBS Submission:** Use the outputs and documentation (CV, Proposal, Motivation Letter) to finalise the PhD application.
2.  **Paper (Post-acceptance):** Expand the MVP into a full paper, with the Embedding Paradox (Predictive GRU outperforming causal variants) as the central finding.
3.  **Real Data:** Apply the validated framework to Danish Register Data (IDA/Statistics Denmark) for empirical results.
4.  **Monte Carlo Study:** Run the pipeline across multiple seeds and DGP specifications to strengthen the conclusions.
